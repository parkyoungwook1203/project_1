# 방언과 우리말, 딥러닝으로 잇(it)다

## 프로젝트 목표
- **제주 방언 ↔ 표준어 번역 모델 구축**

### 문제 배경
- 고령층 및 지역 방언 사용자들의 **디지털 서비스 접근성 문제**
- 콜센터 및 AI 음성 서비스에서의 **방언 인식 한계 → 소통 장애**
- **방언-표준어 자동 변환 모델 개발**을 통한 디지털 소외 해소 필요

---

## 데이터: 한국어 방언 발화 (제주도, AI Hub)
- 데이터 구조: **음성 데이터(wav)** + **텍스트 데이터(json)**
- 음성 데이터: 약 **3,000시간 정제 음성**
- 텍스트 데이터: 원문 표준어 + 방언 특성을 고려한 **이중 전사 텍스트**

### JSON 구조 예시
```json
{
  "id": "데이터 파일 아이디",
  "start": "발화 시작 시간",
  "end": "발화 종료 시간",
  "speaker_id": "화자 아이디",
  "standard_form": "표준어 문장",
  "dialect_form": "방언 문장",
  "eojeolList": [
    {"eojeol": "방언 어절", "standard": "표준어 어절", "isDialect": true}
  ]
}
```
## EDA 및 전처리

실험적으로 5개 JSON 파일을 합쳐서 전처리를 진행 → 두 가지 방식 비교
| 구분             | 전처리 조건                                                                                        | 결과            | 문제점                                 |
| -------------- | --------------------------------------------------------------------------------------------- | ------------- | ----------------------------------- |
| **1안 (강력 정제)** | - 모든 공백 제거<br>- 숫자 제거<br>- 영문 익명값 제거<br>- 특수문자 제거<br>- 불완전한 쌍 제거<br>- 동일 표현 제거<br>- 표준어 중복 제거 | **205,719 행** | - 띄어쓰기 손실 → 의미 왜곡<br>- 방언 데이터 소실    |
| **2안 (완화 정제)** | - 앞뒤 공백만 제거<br>- 특수문자 일부 유지 (!, ?)<br>- 기호만 남은 행 제거<br>- 표준어 중복 허용 → 방언 다양성 확보                | **381,599 행** | - 비속어/은어 포함<br>- 하나의 표준어 ↔ 여러 방언 매핑 |

### 전처리 주요 항목

- eojeolList 기반 어절 단위 전처리

- 숫자, 영어(익명 표시) 제거

- 특수문자 처리 전략 (보존/삭제 규칙 설정)

- 동일 표현 / 불완전한 쌍 제거 및 대표 표준어 선정

## 모델 및 파인튜닝
사용 모델

1. Llama-3-open-ko-8B

2. Llama-3-korean-Bllossom-8B

### [ 1차 실험 (어절 기반) ]

| 모델                         | 데이터       | 시간     | Loss | 비고         |
| -------------------------- | --------- | ------ | ---- | ---------- |
| 1. Llama-3-open-ko-8B         | 20,000 어절 | 3h 30m | 0.56 |            |
| 2. Llama-3-korean-Bllossom-8B | 20,000 어절 | 3h 50m | 0.53 | 성능 큰 차이 없음 |

#### 문제점

- Epoch=20 설정 → 오버피팅 가능성

- 데이터 부족 / 불균형

- 모델 구조 단순 → 학습 한계

### [ 2차 실험 (문장 기반) ]

두가지 모델별 성능차이가 없기때문에 1번 모델만 사용

전환 이유: 어절 기반 학습은 문맥 반영이 부족 → 문장 단위 학습으로 변경

| 데이터       | 학습 시간  | Loss |
| --------- | ------ | ---- |
| 15,000 문장 | 7h 30m | 1.11 |
| 20,000 문장 | 8h 40m | 1.05 |

15,000, 20,000 개 를 학습시킨 두가지 모델 생성
1. Model_15
2. Model_20

## 평가

방언은 표현의 다양성 때문에 BLEU 보다는 BERT score 가 더 적합할 것이라 예상됨

```python
평가 지표

- BLEU → n-gram 기반 정량 비교 (단어/어절 일치 중심)
- BERTScore → 의미 유사도 기반 (문장 의미 중심, 방언 번역 적합)
```

### 단어평가

| 단어 200개 평가 | 수치 |
| ----------- | --------- |
| 평균 BLEU | 0.23 |
| 정확히 일치 | 29% |
| 최소 BLEU | 0 |
| 평균 BERT score | 0.88 |
| 최소 BERT socre | 0.74 |

- BLEU 점수는 낮지만 의미 일치는 양호
- 의역 성향 강한 방언 특성 감안 필요

#### 예시
| 방언 | 표준어 | 모델 예측 |
| ------ | ------ | ------ |
| 만낭 | 만나서 | 만나그네 |
| 거예 | 거예요 | 게우꽝 |
| 그믄 | 그러면 | 그러믄 |



### 문장 평가

#### [ Model_15 ]

| 문장 1,000개 평가(BLEU) | 수치 |
| ----------- | --------- |
| 평균 BLEU | 0.0587 |
| 최솟값 | 0 |
| 최댓값 | 0.70 |
| 정확히 일치 | 0% |

| 문장 1,000개 평가(BERT) | 수치 |
| ----------- | --------- |
| 평균 BERT socre | 0.86 |
| 최솟값 | 0.78 |
| 최댓값 | 0.99 |


- 직접적 정답률은 낮지만 의미 전달력은 있는 경우가 다수
- 자연스러운 방언 변환의 평가 기준은 정확히 일치보다 의미 중심 평가가 더 적합


<img width="1369" height="209" alt="image" src="https://github.com/user-attachments/assets/ff89db6a-c575-46d2-8b23-160545d75362" />

#### [ Model_20 ]

| 문장 3,000개 평가(BLEU) | 수치 |
| ----------- | --------- |
| 평균 BLEU | 0.0636 |
| 최솟값 | 0 |
| 최댓값 | 0.88 |
| 정확히 일치 | 0.2 % |

| 문장 3,000개 평가(BERT) | 수치 |
| ----------- | --------- |
| 평균 BERT socre | 0.86 |
| 최솟값 | 0.73 |
| 최댓값 | 1 |

- 앞선 평가와 동일하게 BLEU 수치는 적지만 BERT socre 은 양호


<img width="1242" height="242" alt="image" src="https://github.com/user-attachments/assets/3403eadc-8d0b-4d25-8b41-4c491c947a0f" />




# STT

현재 상용화 되어있는 STT 모델은 표준어를 중심으로 학습되어있어 방언인식률이 매우 낮음
또한 가지고 있는 음성파일의 발음이 뭉게져서 음성인식의 한계가 있음

그래서 방언=> 표준어로 번역하는것이 아닌 표준어 => 방언으로 번역

openai_wisper 사용

# 프로젝트 성과
1. 제주 방언 <-> 표준어 자동 변환 모델 구축 가능성 확인
2. 정제된 병렬 데이터와 프롬프트 설계를 통해 => 의미 보존 + 자연스러운 번역 가능
3. BLEU 점수 한계 존재하나, Bert score 기반 평가에서 안정성 확보

# 보안점
1. 더 많은 제주방언 학습시 더 정확한 번역 성능 기대할 수 있음
2. 파인튜닝 코드 최적화 및 코드개선으로 학습 시간과 번역 정확도 향상 기대 할 수 있음
3. 방언의 STT 모델 개발하여 방언 => 표준어로 갈 수 있다면 제주 지역 음성서비스 영역 확장 가능



# 배운점
1. 데이터 정제 : json 파일의 필요한 부분 정제능력 향상
2. 허깅페이스 : 허깅페이스 사용법과 활용 능력 향상
3. LLM & 파인튜닝 : torch 를 사용해 torch 역량 확보 및 향상, 방언의 경우 어절이 아닌 문장으로 학습해야지 제대로된 학습 가능 
4. STT & TTS : STT와 TTS 의 역량 향상
5. 




























