# 방언과 우리말, 딥러닝으로 잇(it)다



## 목표 : 제주 방언을 표준어로 번역
## 문제 배경 
- 고령층 및 지역 방언 사용자들의 디지털 서비스 접근성 문제

- 콜센터 및 AI 음성 서비스에서 방언 인식 한계로 인한 소통 장애

- 방언-표준어 자동 변환 AI 모델 개발을 통한 디지털 소외 해소 필요

## 데이터 : 한국어 방언 발화(제주도) - Ai Hub 
- 데이터 구조 : 음성 데이터(wav), 텍스트 데이터(json)

- 음성 데이터 : 3,000시간 정제된 음성데이터

- 텍스트 데이터 : 총 50건의 원본 표준어 텍스트 및 방언 특성을 고려한 이중전사 텍스

[JSON 구조 예시]

<img width="400" height="503" alt="Image" src="https://github.com/user-attachments/assets/3d013fe6-3bcd-4133-9533-290e2fa91045" />



## EDA 
```
[JSON 구조]
```
id : 데이터 파일 아이디

start : 발화 시작 시간

end : 발화 종료 시간

speaker_id : 화자 아이디

standard_form : 표준어

dialect_form : 방언

eojeolList : 문장을 어절로 분해

eojeol : 방언 어절

standard : 표준어 어절

isDialect : 방언 여부(True/False)


** ex) isDialect : False => 방언 어절과 표준어 어절 똑같음 **
```
[전처리]
```
eojeoList안에 있는 어절기반 단어 및 문장 사용

1, 2 안으로 나눠서 전처리 진행



실험적으로 5개의 json 파일 합쳐서 진행

[1안]
- 모든 공백 제거: 각 어절의 시작과 끝에 있는 공백은 물론 모든 공백 제거

- 숫자 제거: "1호점", "6호점" 등 지명으로 사용된 숫자 표현은 모델 혼동을 줄이기 위해 삭제 
방언 학습에 영향이 덜가는 부분 제거

- 영문 익명값 제거: 'name', 'xx', 'company' 등 익명 처리된 영어 항목은 제거

- 특수문자 제거: ., ,, !, ?, # 등의 불필요한 특수기호는 전부 삭제하여 모델이 텍스트 의미에만 집중

- 불완전한 쌍 제거: 방언은 존재하지만 표준어가 비어 있는 경우, 해당 row는 제외
 → 예: ("가난해요", "") → 제거 대상

- 동일 표현 제거: dialect와 standard가 완전히 같은 경우는 제주도 방언으로서의 가치가 없다고 판단하여 제거
 → 예: ("그래요", "그래요") → 제거 대상

- 표준어 중복 제거: 하나의 표준어에 여러 방언이 매핑된 경우, 가장 빈도 높은 방언 1개만 남김
→ 이를 통해 방언 1 : 표준어 1의 일관된 구조 유지

총 행 수 : 205,719
열 수 : 2

[문제점]
- 말 그대로 eojeol list 이지만 데이터에 문장으로 들어가 있는 데이터도 있어서 띄어쓰기를 전부 삭제시 말의 의미가 불명확해짐
- 
- !, ?만 들어가있는 어절값을 찾아서 다시 적용시켜야됨 → 해당 특수문자는 재적용 필요
- 
- 방언-표준어 1:1 매핑 한 결과 다양한 방언들의 데이터 소실이 됨 (모델 일반화 저해)

[2안]
- 앞뒤 불필요한 공백 제거: 각 어절의 시작과 끝에 있는 공백은 제거하고, 의미가 있는 중간공백은 유지 
→ 예: " 가 봐 봐 " → "가는 것도 좋겠어"

- 특수문자 제거: ., ,, # 등 불필요한 특수기호는 모두 삭제하고, !, ?는 어미에 위치한 경우에만 감탄문이나 의문문으로 간주하여 유지

- 기호만 남은 행 제거 (!,?만 있는경우) : 텍스트 없이 !, ?만 포함된 데이터는 모두 삭제
→ 예: "?", "!" 등

- 표준어 중복 허용 + 방언 다양성 확보: 하나의 방언에 여러 표준어가 매핑되어 있는 경우, 가장 빈도가 높은 표준어 하나만 남기고 나머지는 제거하여 방언은 중복없이 유지 

총 행 수 : 381,599
열 수 : 2

[문제점]
- 일부 방언 데이터에 비속어, 은어, 표준어 자체가 포함되어 있음
- 하나의 표준어 표현에 대해 서로 다른 여러 방언 표현이 매핑되는 구조 존재 => 예: 가보다 에 대해 가봐수과, 가봐수

## 파인튜닝 모델 선정

총 2가지 모델을 선택해 진행

1. Llama-3-open-ko-8B

2. Llama-3-korean-Bllossom-8B

[모델 1]
20,000개 어절 학습 3h30m loss : 0.56

[모델 2]
20,000개 어절 학습 3h50m loss: 0.53

학습 시간과 loss를 봤을때 큰차이가 없기때문에 앞으로는 모델 1 만 사용해서 진행

표준어를 넣어봤을때 
표준어: 그래서 -> 사투리: 겅핸예게게게게게

제대로 번역하지는 못하는 문제 발생

왜 그럴까?
1. 너무 과한 epoch => loss 를 줄이기 위해 20의 epoch 를 주었지만 오버피팅의 문제가 생길 수 있음
2. 데이터 부족 및 불균형 => 데이터의 량의 부족 혹은 품질 문제로 제대로 학습하지 못했을 가능성있음
3. 모델이 너무 간단한 구조 => 너무 간단한 모델 구성으로 제대로 학습하지 못했을 가능성있음

[2차 실험]
- 변경점
- 1. 문장 기반 학습으로 전환 => 어절로 학습시 문장의 의미가 제대로 학습 되지 않음 방언 특성상 문장전체를 학습하는게 좋은 결과를 도출할 것이라 생각됨
  2. BLEU/ BERT score 중심 성능 평가로 진행
```
BLEU : n_gram 기반 정량 비교, 단어 순서 중심 평가
BERT score : 의미 기반 유사도 평가, 문장 의미 중심
방언 번역은 표현 다양성 때문에 BLEU 보다 BERT socre를 더 중요하게 봐야함
```
  
데이터 량의 부족인지 검증하기위해 20,000개 15,000개 학습

15,000개 문장 학습 => 7h 30min loss : 1.11
20,000개 문장 학습 => 8h 40m loss : 1.05

[model_15] 
단어 200 개 평가

<img width="417" height="342" alt="image" src="https://github.com/user-attachments/assets/7c6ba12a-ad03-4ee1-b84c-6f6d5d469319" />

- BLEU 점수는 낮지만 의미 일치는 양호
- 의역 성향 강한 방언 번역 특성 감안 필요



문장 1,000개 평가

<img width="219" height="52" alt="image" src="https://github.com/user-attachments/assets/16954ec6-3c1f-46e9-a758-994ff56f4da3" />

- BLEU 수치는 낮지만 BERT score 은 높게 나옴
 
EX)

label : 그렇게 좋아하지 안
표준어 : 그렇게 좋아하지 않아
모델 예측 : 경 잘 안좋아하맨

EX2)

label : 아 나 나 신발은 이 년 된거 닮아
표준어 : 아 나 나 신발은 이 년 된거 같아
모델 예측 : 아 나 나 신발은 이 년 되난게

[model_20]
3,000 개 문장 평가










-번외-
프롬프트 테스트 

chat GPT 는 번역을 잘 해줄까?
대규모 언어모델인 GPT 는 과연 제주 방언 번역 성능이 좋을까? 라는 궁금증이 생겨 실험해보았다

- '제주 방언'이라는 조건어가 프롬프트 안에 들어갈 때와 아닐 때, 출력 결과의 정확도나 자연스러움에 유의미한 차이가 있는지를 확인
- A안 : '가봐수과는' 제주 방언인데, 표준어로 번역해줘
- b안 : '가봐수과'를 표준어로 바꿔줘줘

결과

<img width="607" height="252" alt="image" src="https://github.com/user-attachments/assets/8d577fda-d4a2-43e9-9227-5e7e5efc5c16" />

제주 방언 포함시 더 정확하고 일관된 표준어 출력

GPT 가 내놓은 답변이 모두 정답이 아닌다 => 방언특성상 다의적 표현이 존재함









