🗣️ 방언과 우리말, 딥러닝으로 잇(it)다
🎯 프로젝트 목표

제주 방언 ↔ 표준어 번역 모델 구축

문제 배경

고령층 및 지역 방언 사용자들의 디지털 서비스 접근성 문제

콜센터 및 AI 음성 서비스에서의 방언 인식 한계 → 소통 장애

방언-표준어 자동 변환 모델 개발을 통한 디지털 소외 해소 필요

📂 데이터: 한국어 방언 발화 (제주도, AI Hub)

데이터 구조: 음성 데이터(wav) + 텍스트 데이터(json)

음성 데이터: 약 3,000시간 정제 음성

텍스트 데이터: 원문 표준어 + 방언 특성을 고려한 이중 전사 텍스트

JSON 구조 예시
{
  "id": "데이터 파일 아이디",
  "start": "발화 시작 시간",
  "end": "발화 종료 시간",
  "speaker_id": "화자 아이디",
  "standard_form": "표준어 문장",
  "dialect_form": "방언 문장",
  "eojeolList": [
    {"eojeol": "방언 어절", "standard": "표준어 어절", "isDialect": true}
  ]
}


isDialect = False → 방언 어절과 표준어 어절이 동일한 경우

🔎 EDA 및 전처리

실험적으로 5개 JSON 파일을 합쳐서 전처리를 진행 → 두 가지 방식 비교

구분	전처리 조건	결과	문제점
1안 (강력 정제)	- 모든 공백 제거
- 숫자 제거
- 영문 익명값 제거
- 특수문자 제거
- 불완전한 쌍 제거
- 동일 표현 제거
- 표준어 중복 제거	205,719 행	- 띄어쓰기 손실 → 의미 왜곡
- 방언 데이터 소실
2안 (완화 정제)	- 앞뒤 공백만 제거
- 특수문자 일부 유지 (!, ?)
- 기호만 남은 행 제거
- 표준어 중복 허용 → 방언 다양성 확보	381,599 행	- 비속어/은어 포함
- 하나의 표준어 ↔ 여러 방언 매핑
전처리 주요 항목

eojeolList 기반 어절 단위 전처리

숫자, 영어(익명 표시) 제거

특수문자 처리 전략 (보존/삭제 규칙 설정)

동일 표현 / 불완전한 쌍 제거 및 대표 표준어 선정

ThreadPoolExecutor 활용 → 병렬 처리로 속도 개선

🧠 모델 및 파인튜닝
사용 모델

Llama-3-open-ko-8B

Llama-3-korean-Bllossom-8B

1차 실험 (어절 기반)
모델	데이터	시간	Loss	비고
Llama-3-open-ko-8B	20,000 어절	3h 30m	0.56	
Llama-3-korean-Bllossom-8B	20,000 어절	3h 50m	0.53	성능 큰 차이 없음

⚠️ 문제점 요약

Epoch=20 설정 → 오버피팅 가능성

데이터 부족 / 불균형

모델 구조 단순 → 학습 한계

2차 실험 (문장 기반)

전환 이유: 어절 기반 학습은 문맥 반영이 부족 → 문장 단위 학습으로 변경

평가 지표:

BLEU → n-gram 기반 정량 비교 (단어/어절 일치 중심)

BERTScore → 의미 유사도 기반 (문장 의미 중심, 방언 번역 적합)

데이터	학습 시간	Loss
15,000 문장	7h 30m	1.11
20,000 문장	8h 40m	1.05
예시 결과
Label   : 그렇게 좋아하지 안
표준어  : 그렇게 좋아하지 않아
예측    : 경 잘 안좋아하맨

Label   : 아 나 나 신발은 이 년 된거 닮아
표준어  : 아 나 나 신발은 이 년 된거 같아
예측    : 아 나 나 신발은 이 년 되난게


관찰

BLEU 점수: 낮음

BERTScore: 높음 → 의미 전달은 양호 (의역 성향 반영)

💡 번외: 프롬프트 실험 (ChatGPT)

실험 목적: GPT(대규모 언어모델)가 제주 방언 번역에 어느 정도 성능을 내는지 확인

조건 비교

A안: "가봐수과는 제주 방언인데, 표준어로 번역해줘"

B안: "가봐수과를 표준어로 바꿔줘"

조건	결과
제주 방언 조건어 포함	더 정확하고 일관된 번역
조건어 미포함	직역/오해 발생 가능

⚠️ 한계

방언 특성상 다의적 표현 多 → 정답이 여러 개일 수 있음

GPT 출력은 보조 수단 → 라벨 데이터 대체 불가

✅ 결론 및 시사점

BLEU 낮음 / BERTScore 높음
→ 방언 번역 평가는 **의미 중심(BERTScore)**이 더 적합

데이터 전처리와 품질 → 모델 성능에 핵심적 영향

문장 단위 학습이 어절 단위보다 문맥 보존 측면에서 유리

프롬프트 실험을 통해 입력 설계 중요성 확인

향후 개선 방향:

데이터 증강 및 불균형 해소

STT(Whisper) 도메인 튜닝

Top-N 기반 의미 평가 지표 추가

🔭 활용 가능 분야

실시간 통역 서비스

자막 자동 변환 (영상/방송)

AI 콜센터 상담 지원

지역 언어 보존 및 교육 콘텐츠

👥 팀원

김수광

박영욱

방서연

(DS37기 딥러닝 프로젝트 1조)
